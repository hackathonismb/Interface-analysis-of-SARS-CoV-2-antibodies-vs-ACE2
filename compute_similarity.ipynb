{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Script to compute similarity matrices for subregion electrostatics of each PDB. Will need to plot them too. Hmmm -> matrix heatmap.\n",
    "\n",
    "## Load the data ##\n",
    "\n",
    "pdbs = []\n",
    "potentials = {}\n",
    "data_folder = Path('data')\n",
    "with open(data_folder / 'all_spike_strs_regions_pot.csv', 'r') as f:\n",
    "    header = next(f).split(',')\n",
    "    print('column names:', header)\n",
    "    data = defaultdict(dict)\n",
    "    for line in f:\n",
    "        mm = line.split(',')\n",
    "\n",
    "        if len(mm) == 3:\n",
    "            key_AG, key_region, potential = mm\n",
    "            # key_region = int(key_region.split['_'][-1]) # transform region key to int?\n",
    "            data[key_AG].update({key_region: float(potential)})\n",
    "\n",
    "data = dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data).T\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 8 pdbs have 20 regions defined: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.notna().sum(axis=1).value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,'region_1':'region_20'].dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continue with remaining complete list of antigens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_triangle(df):\n",
    "    \"\"\"Compute the correlation matrix, returning only unique values.\"\"\"\n",
    "    lower_triangle = pd.DataFrame(\n",
    "        np.tril(np.ones(df.shape), -1)).astype(bool)\n",
    "    lower_triangle.index, lower_triangle.columns = df.index, df.columns\n",
    "    return df.where(lower_triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dist= {}\n",
    "metrics = ['cosine', 'euclidean', 'l2', 'manhattan', 'l1', 'hamming', 'chebyshev'] # 'jaccard' excluded as it's for binary data\n",
    "for _metric in metrics:\n",
    "    dict_dist[_metric] = pd.DataFrame(pairwise_distances(X=df, metric=_metric), index=df.index, columns=df.index)\n",
    "    dict_dist[_metric] = lower_triangle(dict_dist[_metric]).stack()\n",
    "df_metrics = pd.DataFrame(dict_dist)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "$ z = \\frac{x - min(X)}{max(X)-min(X)}$\n",
    "\n",
    "where\n",
    "- $x$: a single correlation value of a metric\n",
    "- $X$: the set of correlations for a single metric\n",
    "- $z$: a singe *normalized* correlation value of a metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_metrics = df_metrics.describe()\n",
    "stats_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_min = stats_metrics.loc['min'] ## doesn't give correct answer, because of dtype errors?\n",
    "X_max = stats_metrics.loc['max'] ## doesn't give correct answer?\n",
    "#df_metrics['cosine'] = pd.to_numeric(df_metrics.cosine)\n",
    "#df_metrics['cosine'].max()\n",
    "X_min = df_metrics.min()\n",
    "X_max = df_metrics.max()\n",
    "X_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_normalized = (df_metrics - X_min) / (X_max - X_min)\n",
    "df_metrics_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the mean metrics heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metrics = df_metrics_normalized.mean(axis=1).unstack()\n",
    "mean_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the matplotlib figure\n",
    "matplotlib.rc('xtick', labelsize=16)\n",
    "matplotlib.rc('ytick', labelsize=16)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30,20)) \n",
    "\n",
    "ax = sns.heatmap(mean_metrics, annot=True, fmt='0.2f', cmap=\"RdBu_r\", ax=ax, annot_kws={\"size\": 28} ) #annot=labels, fmt='',annot_kws={\"size\": 14}, cmap=\"RdBu_r\") #fmt=\"0.2f\",  cmap=\"RdBu_r\")\n",
    "ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 28)\n",
    "ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize = 28)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Histogram of similarity matrix values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mean_metrics.to_numpy().flatten())\n",
    "plt.ylabel('Count', fontsize=18)\n",
    "plt.xlabel('Similarity score', fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute and plot 'Super' similarity entries by taking average of similarity scores and select those with average above 0.6 (threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_sum = mean_metrics.sum(axis=1)\n",
    "rows_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_sum = mean_metrics.sum(axis=0)\n",
    "columns_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sum = np.concatenate(([0],rows_sum.to_numpy())) ## insert leading zero.\n",
    "row_sum\n",
    "column_sum = np.concatenate((columns_sum.to_numpy(),[0])) ## insert last zero.\n",
    "column_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add arrays together, and plot histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_similarity = ( row_sum + column_sum ) / len( row_sum )\n",
    "\n",
    "plt.hist(super_similarity)\n",
    "plt.ylabel('Count', fontsize=18)\n",
    "plt.xlabel('Super similarity score', fontsize=18)\n",
    "\n",
    "plt.axvline(x=0.6,lw=3,c='tab:orange')\n",
    "\n",
    "plt.title('Super similarity histogram', fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get indices of super similars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb_indices = []\n",
    "for index in range(0, len(super_similarity)) :\n",
    "    if super_similarity[index] > 0.6:\n",
    "        pdb_indices.append(index)\n",
    "        \n",
    "pdb_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get pdb ids of super similars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_labels = np.array(mean_metrics.index)\n",
    "row_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_labels = np.array(mean_metrics.columns)\n",
    "column_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pdb_ids = np.insert(row_labels,0,column_labels[0])\n",
    "all_pdb_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_similar_pdbs = all_pdb_ids[pdb_indices]\n",
    "super_similar_pdbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region by region comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 20\n",
    "residues = 330\n",
    "\n",
    "## df.iloc[:,0] ## column 1 = region 1\n",
    "dict_dist= {}\n",
    "metrics = ['cosine', 'euclidean', 'l2', 'manhattan', 'l1', 'hamming', 'chebyshev'] # 'jaccard' excluded as it's for binary data\n",
    "for _metric in metrics:\n",
    "    dict_dist[_metric] = pd.DataFrame(pairwise_distances(X=df[['region_{}'.format(region)]].to_numpy(), metric=_metric), index=df.index, columns=df.index)\n",
    "    dict_dist[_metric] = lower_triangle(dict_dist[_metric]).stack()\n",
    "df_metrics = pd.DataFrame(dict_dist)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_metrics = df_metrics.describe()\n",
    "X_min = stats_metrics.loc['min']\n",
    "X_max = stats_metrics.loc['max']\n",
    "df_metrics_normalized = (df_metrics - X_min) / (X_max - X_min)\n",
    "mean_metrics = df_metrics_normalized.mean(axis=1).unstack()\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "matplotlib.rc('xtick', labelsize=18)\n",
    "matplotlib.rc('ytick', labelsize=18)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30,20)) \n",
    "\n",
    "ax = sns.heatmap(mean_metrics, annot=True, fmt='0.2f', cmap=\"RdBu_r\", ax=ax, annot_kws={\"size\": 28} ) #annot=labels, fmt='',annot_kws={\"size\": 14}, cmap=\"RdBu_r\") #fmt=\"0.2f\",  cmap=\"RdBu_r\")\n",
    "ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 28)\n",
    "ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize = 28)\n",
    "\n",
    "plt.title('Dissimilarity between Region{} Residues {}-{}'.format(region,residues+region*10 - 10,residues+region*10), fontsize = 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb1 = '7lyn'\n",
    "pdb2 = '7eb5'\n",
    "\n",
    "pairwise_region = []\n",
    "\n",
    "for region in range(1,21):\n",
    "    dict_dist= {}\n",
    "    metrics = ['cosine', 'euclidean', 'l2', 'manhattan', 'l1', 'hamming', 'chebyshev'] # 'jaccard' excluded as it's for binary data\n",
    "    for _metric in metrics:\n",
    "        dict_dist[_metric] = pd.DataFrame(pairwise_distances(X=df[['region_{}'.format(region)]].to_numpy(), metric=_metric), index=df.index, columns=df.index)\n",
    "        dict_dist[_metric] = lower_triangle(dict_dist[_metric]).stack()\n",
    "    df_metrics = pd.DataFrame(dict_dist)\n",
    "    stats_metrics = df_metrics.describe()\n",
    "    X_min = stats_metrics.loc['min']\n",
    "    X_max = stats_metrics.loc['max']\n",
    "    df_metrics_normalized = (df_metrics - X_min) / (X_max - X_min)\n",
    "    mean_metrics = df_metrics_normalized.mean(axis=1).unstack()\n",
    "\n",
    "\n",
    "    if pdb1 in mean_metrics[pdb2]:\n",
    "        pairwise_region.append(mean_metrics[pdb2][[pdb1]])\n",
    "    elif pdb2 in mean_metrics[pdb1]:\n",
    "        pairwise_region.append(mean_metrics[pdb1][[pdb2]])\n",
    "        \n",
    "      \n",
    "# Set up the matplotlib figure\n",
    "matplotlib.rc('xtick', labelsize=18)\n",
    "matplotlib.rc('ytick', labelsize=18)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30,20)) \n",
    "\n",
    "ax = sns.heatmap(pairwise_region, annot=True, fmt='0.2f', cmap=\"RdBu_r\", ax=ax, annot_kws={\"size\": 36} ) #annot=labels, fmt='',annot_kws={\"size\": 14}, cmap=\"RdBu_r\") #fmt=\"0.2f\",  cmap=\"RdBu_r\")\n",
    "#ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 36)\n",
    "#ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize = 28)\n",
    "#ax.set_yticklabels([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], fontsize = 36)\n",
    "ax.set_yticklabels(['330-340','340-350','350-360','360-370','370-380','380-390','390-400','400-410','410-420','420-430','430-440','440-450','450-460','460-470','470-480','480-490','490-500','500-510','510-520','520-530'], rotation=0, fontsize = 36)\n",
    "\n",
    "plt.ylabel('Residues',fontsize = 36)\n",
    "\n",
    "plt.title('Dissimilarity between {} {}'.format(pdb1,pdb2), fontsize = 36)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('isbm2021hack': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "113c3b49a745529ccba092b262ddb34345e8f62d7938ed9b284d5ef9ea6d628d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}