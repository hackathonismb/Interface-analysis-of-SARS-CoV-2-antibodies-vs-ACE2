{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# Script to compute similarity matrices for subregion electrostatics of each PDB. Will need to plot them too. Hmmm -> matrix heatmap.\n",
    "\n",
    "## Load the data ##\n",
    "\n",
    "pdbs = []\n",
    "potentials = {}\n",
    "data_folder = Path(\"data\")\n",
    "with open(data_folder / \"all_spike_strs_regions_pot.csv\", \"r\") as f:\n",
    "    header = next(f).split(\",\")\n",
    "    print(\"column names:\", header)\n",
    "    data = defaultdict(dict)\n",
    "    for line in f:\n",
    "        mm = line.split(\",\")\n",
    "\n",
    "        if len(mm) == 3:\n",
    "            key_AG, key_region, potential = mm\n",
    "            # key_region = int(key_region.split['_'][-1]) # transform region key to int?\n",
    "            data[key_AG].update({key_region: float(potential)})\n",
    "data = dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data).T\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only a 98 have 21 regions defined: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.notna().sum(axis=1).value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, \"region_1\":\"region_19\"].dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continue with remaining complete list of antigens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_triangle(df):\n",
    "    \"\"\"Compute the correlation matrix, returning only unique values.\"\"\"\n",
    "    lower_triangle = pd.DataFrame(np.tril(np.ones(df.shape), -1)).astype(bool)\n",
    "    lower_triangle.index, lower_triangle.columns = df.index, df.columns\n",
    "    return df.where(lower_triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dist = {}\n",
    "metrics = [\n",
    "    \"cosine\",\n",
    "    \"euclidean\",\n",
    "    \"l2\",\n",
    "    \"manhattan\",\n",
    "    \"l1\",\n",
    "    \"hamming\",\n",
    "    \"chebyshev\",\n",
    "]  # 'jaccard' excluded as it's for binary data\n",
    "for _metric in metrics:\n",
    "    dict_dist[_metric] = pd.DataFrame(\n",
    "        pairwise_distances(X=df, metric=_metric), index=df.index, columns=df.index\n",
    "    )\n",
    "    dict_dist[_metric] = lower_triangle(dict_dist[_metric]).stack()\n",
    "df_metrics = pd.DataFrame(dict_dist)\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "$ z = \\frac{x - min(X)}{max(X)-min(X)}$\n",
    "\n",
    "where\n",
    "- $x$: a single correlation value of a metric\n",
    "- $X$: the set of correlations for a single metric\n",
    "- $z$: a singe *normalized* correlation value of a metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_metrics = df_metrics.describe()\n",
    "stats_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_min = stats_metrics.loc[\"min\"]\n",
    "X_max = stats_metrics.loc[\"max\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_normalized = (df_metrics - X_min) / (X_max - X_min)\n",
    "df_metrics_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the mean metrics heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metrics = df_metrics_normalized.mean(axis=1).unstack()\n",
    "mean_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the matplotlib figure\n",
    "matplotlib.rc(\"xtick\", labelsize=16)\n",
    "matplotlib.rc(\"ytick\", labelsize=16)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 20))\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    mean_metrics, annot=False, cmap=\"RdBu_r\", ax=ax\n",
    ")  # annot=labels, fmt='',annot_kws={\"size\": 14}, cmap=\"RdBu_r\") #fmt=\"0.2f\",  cmap=\"RdBu_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
